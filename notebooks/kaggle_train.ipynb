{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# ü´Å Pneumothorax AI ‚Äî Global Pre-training (Kaggle)\n",
    "**T√úBƒ∞TAK 2209-A | Ahmet Demir | Dokuz Eyl√ºl √úniversitesi**\n",
    "\n",
    "**Avantajlar:**\n",
    "- NIH Chest X-rays veri seti zaten Kaggle'da ‚Äî tekrar indirme yok (~42 GB klasik indirme atlanƒ±r)\n",
    "- Haftalƒ±k 30 saat √ºcretsiz GPU (P100 veya T4)\n",
    "- Checkpoint'ler Kaggle Output'a kaydedilir, sonra Drive/GitHub'a kopyalanabilir\n",
    "\n",
    "**Gereksinimler:**\n",
    "- Kaggle Notebook ‚Üí Settings ‚Üí Accelerator: **GPU P100** se√ß\n",
    "- Internet: **ON** (pip install i√ßin)\n",
    "- Bu notebook'u √ßalƒ±≈ütƒ±rmadan √∂nce NIH dataset'i **Input** olarak ekle:\n",
    "  - `+ Add Data` ‚Üí Search: `nih-chest-xrays` ‚Üí `NIH Chest X-rays` (NIH Clinical Center)\n",
    "  - Veri yolu: `/kaggle/input/nih-chest-xrays/`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-gpu",
   "metadata": {},
   "source": ["## 0. GPU Kontrol√º"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gpu-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print('GPU :', torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'YOK ‚Äî Accelerator > GPU se√ß!')\n",
    "print('CUDA:', torch.version.cuda)\n",
    "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-nih",
   "metadata": {},
   "source": [
    "## 1. NIH Veri Yolunu Kontrol Et\n",
    "> Input olarak `nih-chest-xrays` eklendiyse `/kaggle/input/nih-chest-xrays/` altƒ±nda g√∂r√ºnmeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nih-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess\n",
    "\n",
    "NIH_INPUT = '/kaggle/input/nih-chest-xrays'\n",
    "if os.path.exists(NIH_INPUT):\n",
    "    count = int(subprocess.check_output(\n",
    "        f'find {NIH_INPUT} -name \"*.png\" | wc -l', shell=True\n",
    "    ).decode().strip())\n",
    "    print(f'‚úì NIH veri seti bulundu: {count:,} PNG g√∂r√ºnt√º')\n",
    "    print('  Klas√∂rler:', os.listdir(NIH_INPUT)[:5])\n",
    "else:\n",
    "    print('[!] NIH veri seti bulunamadƒ±!')\n",
    "    print('    ‚Üí Saƒü panelden \"+Add Data\" ‚Üí \"nih-chest-xrays\" ekle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-clone",
   "metadata": {},
   "source": ["## 2. Projeyi Klonla"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clone",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO = 'https://github.com/ahmetai-cell/pneumothorax-ai-detection'\n",
    "PROJECT_DIR = '/kaggle/working/pneumothorax-ai-detection'\n",
    "\n",
    "if os.path.exists(PROJECT_DIR):\n",
    "    !cd {PROJECT_DIR} && git pull\n",
    "else:\n",
    "    !git clone {REPO}\n",
    "\n",
    "os.chdir(PROJECT_DIR)\n",
    "print('√áalƒ±≈üma dizini:', os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-deps",
   "metadata": {},
   "source": ["## 3. Baƒüƒ±mlƒ±lƒ±klarƒ± Y√ºkle"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deps",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q \\\n",
    "    segmentation-models-pytorch \\\n",
    "    albumentations \\\n",
    "    pydicom \\\n",
    "    pynrrd \\\n",
    "    wandb \\\n",
    "    tqdm \\\n",
    "    fpdf2 \\\n",
    "    plotly\n",
    "\n",
    "print('‚úì Kurulum tamamlandƒ±')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-nih-link",
   "metadata": {},
   "source": [
    "## 4. NIH Verisini Proje Dizinine Baƒüla\n",
    "Sembolik link ile `/kaggle/input/nih-chest-xrays` ‚Üí `data/raw/global/nih`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nih-link",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "NIH_LOCAL = 'data/raw/global/nih'\n",
    "os.makedirs('data/raw/global', exist_ok=True)\n",
    "os.makedirs('data/processed', exist_ok=True)\n",
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "os.makedirs('results', exist_ok=True)\n",
    "\n",
    "NIH_INPUT = '/kaggle/input/nih-chest-xrays'\n",
    "\n",
    "if os.path.exists(NIH_INPUT):\n",
    "    if not os.path.exists(NIH_LOCAL):\n",
    "        os.symlink(NIH_INPUT, NIH_LOCAL)\n",
    "        print(f'‚úì Symlink olu≈üturuldu: {NIH_LOCAL} ‚Üí {NIH_INPUT}')\n",
    "    else:\n",
    "        print(f'‚úì Zaten mevcut: {NIH_LOCAL}')\n",
    "    # G√∂r√ºnt√º sayƒ±sƒ±nƒ± doƒürula\n",
    "    count = int(subprocess.check_output(\n",
    "        f'find {NIH_INPUT} -name \"*.png\" | wc -l', shell=True\n",
    "    ).decode().strip())\n",
    "    print(f'  Toplam PNG: {count:,}')\n",
    "else:\n",
    "    print('[!] NIH Input eklenmemi≈ü. NIH_LOCAL zaten varsa devam edilebilir.')\n",
    "    # Manual path fallback\n",
    "    for alt in [\n",
    "        '/kaggle/input/nih-chest-xrays/images',\n",
    "        '/kaggle/input/chest-xray-nihcc/images',\n",
    "        '/kaggle/input/nih-chest-xrays',\n",
    "    ]:\n",
    "        if os.path.exists(alt):\n",
    "            print(f'  Alternatif bulundu: {alt}')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-manifest",
   "metadata": {},
   "source": ["## 5. Manifest Olu≈ütur"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manifest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NIH i√ßin manifest olu≈ütur (SIIM yoksa sadece NIH)\n",
    "!python scripts/data_manager.py --build_manifest\n",
    "!python scripts/unify_annotations.py\n",
    "\n",
    "import pandas as pd\n",
    "try:\n",
    "    df = pd.read_csv('data/processed/master_manifest.csv')\n",
    "    print(f'\\n‚úì Manifest: {len(df):,} kayƒ±t')\n",
    "    print(f'  Pozitif: {(df[\"is_pneumo\"]==1).sum():,}')\n",
    "    print(f'  Negatif: {(df[\"is_pneumo\"]==0).sum():,}')\n",
    "    print(f'  Kaynaklar: {df[\"source\"].value_counts().to_dict()}')\n",
    "except Exception as e:\n",
    "    print(f'[!] {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-wandb",
   "metadata": {},
   "source": ["## 6. W&B Giri≈ü (Opsiyonel)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wandb-login",
   "metadata": {},
   "outputs": [],
   "source": [
    "# W&B kullanmak istiyorsan token gir, istemiyorsan h√ºcreyi atla\n",
    "WANDB_KEY = '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'\n",
    "\n",
    "if WANDB_KEY:\n",
    "    !pip install -q --upgrade wandb\n",
    "    import wandb\n",
    "    wandb.login(key=WANDB_KEY, relogin=True)\n",
    "    USE_WANDB = True\n",
    "    print('‚úì W&B baƒülantƒ±sƒ± tamam')\n",
    "else:\n",
    "    USE_WANDB = False\n",
    "    print('W&B atlandƒ±')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-train-header",
   "metadata": {},
   "source": [
    "## 7. Pre-training Ba≈ülat\n",
    "\n",
    "**Kaggle P100'de tahmini s√ºre:**\n",
    "- 1 epoch (112k g√∂r√ºnt√º, batch=32): ~10 dakika  \n",
    "- 50 epoch: ~8-9 saat  \n",
    "- 30 epoch: ~5 saat (√∂neri ‚Äî ilk √ßalƒ±≈ütƒ±rma i√ßin)\n",
    "\n",
    "> ‚ö†Ô∏è Kaggle session 9 saatte kapanabilir. Checkpoint her fold'dan sonra kaydedilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train",
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB_FLAG = '' if USE_WANDB else '--no_wandb'\n",
    "CKPT_DIR   = '/kaggle/working/checkpoints'\n",
    "\n",
    "!python scripts/train_global.py \\\n",
    "    --sources NIH \\\n",
    "    --encoder efficientnet-b0 \\\n",
    "    --img_size 512 \\\n",
    "    --epochs 30 \\\n",
    "    --batch_size 32 \\\n",
    "    --num_folds 5 \\\n",
    "    --lr 1e-4 \\\n",
    "    {WANDB_FLAG} \\\n",
    "    --checkpoint_dir {CKPT_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-results",
   "metadata": {},
   "source": ["## 8. Sonu√ßlar"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "results",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, json, glob\n",
    "\n",
    "results_csv = f'{CKPT_DIR}/../results/global_kfold_results.csv'\n",
    "# Alternatif yollarƒ± dene\n",
    "for p in [results_csv, 'results/global_kfold_results.csv',\n",
    "          f'{CKPT_DIR}/global_kfold_results.csv']:\n",
    "    if os.path.exists(p):\n",
    "        df = pd.read_csv(p)\n",
    "        print('=== K-FOLD SONU√áLARI ===')\n",
    "        print(df.to_string(index=False))\n",
    "        print(f'\\nOrtalama Dice : {df[\"best_dice\"].mean():.4f} ¬± {df[\"best_dice\"].std():.4f}')\n",
    "        print(f'Ortalama AUC  : {df[\"best_auc\"].mean():.4f} ¬± {df[\"best_auc\"].std():.4f}')\n",
    "        break\n",
    "else:\n",
    "    print('Results CSV bulunamadƒ± ‚Äî eƒüitim hen√ºz bitmemi≈ü olabilir')\n",
    "\n",
    "# Base model meta\n",
    "for mp in [f'{CKPT_DIR}/global_base_model_meta.json',\n",
    "           'checkpoints/global_base_model_meta.json']:\n",
    "    if os.path.exists(mp):\n",
    "        meta = json.load(open(mp))\n",
    "        print('\\n=== BASE MODEL ===')\n",
    "        for k, v in meta.items():\n",
    "            print(f'  {k}: {v}')\n",
    "        break\n",
    "\n",
    "# Checkpoint listesi\n",
    "ckpts = glob.glob(f'{CKPT_DIR}/**/*.pth', recursive=True)\n",
    "print(f'\\n  Kaydedilen checkpoint: {len(ckpts)}')\n",
    "for c in sorted(ckpts):\n",
    "    size_mb = os.path.getsize(c) / 1e6\n",
    "    print(f'  {os.path.basename(c):40s}  {size_mb:.1f} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-download",
   "metadata": {},
   "source": [
    "## 9. Checkpoint'i ƒ∞ndir / Y√ºkle\n",
    "\n",
    "Kaggle'da Output'a kaydedilen dosyalarƒ± saƒü paneldeki **Output** sekmesinden indirebilirsin.  \n",
    "Veya Kaggle Dataset olarak kaydet ‚Üí Colab/yerel ortama ekle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "package",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "\n",
    "# T√ºm √∂nemli dosyalarƒ± /kaggle/working/ altƒ±na kopyala (Output'ta g√∂r√ºn√ºr)\n",
    "OUTPUT = '/kaggle/working'\n",
    "\n",
    "files_to_copy = [\n",
    "    (f'{CKPT_DIR}/global_base_model.pth',       f'{OUTPUT}/global_base_model.pth'),\n",
    "    (f'{CKPT_DIR}/global_base_model_meta.json',  f'{OUTPUT}/global_base_model_meta.json'),\n",
    "    ('results/global_kfold_results.csv',          f'{OUTPUT}/global_kfold_results.csv'),\n",
    "]\n",
    "\n",
    "for src, dst in files_to_copy:\n",
    "    if os.path.exists(src):\n",
    "        shutil.copy(src, dst)\n",
    "        print(f'‚úì {os.path.basename(src)} ‚Üí {dst}')\n",
    "    else:\n",
    "        print(f'  - {src} bulunamadƒ±')\n",
    "\n",
    "# Fold checkpoint'leri de kopyala\n",
    "for ckpt in glob.glob(f'{CKPT_DIR}/global_folds/*.pth'):\n",
    "    dst = f'{OUTPUT}/{os.path.basename(ckpt)}'\n",
    "    shutil.copy(ckpt, dst)\n",
    "    print(f'‚úì {os.path.basename(ckpt)}')\n",
    "\n",
    "print(f'\\n‚úì T√ºm dosyalar Output sekmesinde indirilebilir durumda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next-steps",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚úÖ Sonraki Adƒ±m ‚Äî Fine-tuning\n",
    "\n",
    "```bash\n",
    "# Checkpoint'i yerel makineye indir, sonra:\n",
    "cp ~/Downloads/global_base_model.pth checkpoints/\n",
    "\n",
    "# DEU verilerini koy\n",
    "# data/local/dicom/*.dcm\n",
    "# data/local/nrrd/*.nrrd\n",
    "\n",
    "# Fine-tune et (~1-2 saat)\n",
    "python scripts/fine_tune_local.py --freeze_encoder --epochs 20\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
