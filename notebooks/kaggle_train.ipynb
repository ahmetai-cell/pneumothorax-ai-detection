{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# ðŸ« Pneumothorax AI â€” Global Pre-training (Kaggle)\n",
    "**TÃœBÄ°TAK 2209-A | Ahmet Demir | Dokuz EylÃ¼l Ãœniversitesi**\n",
    "\n",
    "**Gereksinimler:** Settings â†’ Accelerator: **GPU P100** | Input: SIIM-ACR | Internet: ON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gpu-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os, subprocess, glob, shutil, json\n",
    "print('GPU :', torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'YOK â€” Settings > GPU P100 seÃ§!')\n",
    "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader 2>/dev/null || true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "find-siim",
   "metadata": {},
   "outputs": [],
   "source": "# SIIM verisini nerede olursa olsun bul\nprint('=== /kaggle/input iÃ§eriÄŸi ===')\nfor root, dirs, files in os.walk('/kaggle/input', topdown=True):\n    depth = root.replace('/kaggle/input', '').count('/')\n    print('  ' * depth + os.path.basename(root) + '/')\n    if depth >= 2:\n        dirs.clear()\n\nSIIM_INPUT = None\n\n# 1) Ã–nce RLE CSV'yi bul â€” dataset root onun yanÄ±nda\nrle_files = glob.glob('/kaggle/input/**/*rle*.csv', recursive=True)\nif rle_files:\n    SIIM_INPUT = os.path.dirname(rle_files[0])\n    print(f'\\nâœ“ SIIM bulundu (RLE): {SIIM_INPUT}')\nelse:\n    # 2) dicom-images-train klasÃ¶rÃ¼nÃ¼ ara\n    dcm_dirs = glob.glob('/kaggle/input/**/dicom-images-train', recursive=True)\n    if dcm_dirs:\n        SIIM_INPUT = os.path.dirname(dcm_dirs[0])\n        print(f'\\nâœ“ SIIM bulundu (dicom-images-train): {SIIM_INPUT}')\n    else:\n        # 3) Herhangi bir .dcm dosyasÄ±ndan Ã¼st dizini Ã§Ä±kar\n        dcm_files = glob.glob('/kaggle/input/**/*.dcm', recursive=True)\n        if dcm_files:\n            # DCM dosyasÄ±nÄ±n bulunduÄŸu klasÃ¶rden yukarÄ± Ã§Ä±karak CSV ara\n            dcm_dir = os.path.dirname(dcm_files[0])\n            candidate = dcm_dir\n            for _ in range(4):\n                if glob.glob(f'{candidate}/*.csv'):\n                    SIIM_INPUT = candidate\n                    break\n                parent = os.path.dirname(candidate)\n                if parent in ('/kaggle/input', '/kaggle', '/'):\n                    SIIM_INPUT = dcm_dir\n                    break\n                candidate = parent\n            if SIIM_INPUT is None:\n                SIIM_INPUT = dcm_dir\n            print(f'âœ“ SIIM (dcm ile) bulundu: {SIIM_INPUT}')\n        else:\n            print('[!] SIIM verisi bulunamadÄ±!')\n\nprint(f'SIIM_INPUT = {SIIM_INPUT}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clone",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO = 'https://github.com/ahmetai-cell/pneumothorax-ai-detection'\n",
    "PROJECT_DIR = '/kaggle/working/pneumothorax-ai-detection'\n",
    "\n",
    "if os.path.exists(PROJECT_DIR):\n",
    "    result = subprocess.run('git pull', shell=True, cwd=PROJECT_DIR, capture_output=True, text=True)\n",
    "    print(result.stdout)\n",
    "else:\n",
    "    subprocess.run(f'git clone {REPO}', shell=True, cwd='/kaggle/working')\n",
    "\n",
    "os.chdir(PROJECT_DIR)\n",
    "print('âœ“ Ã‡alÄ±ÅŸma dizini:', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deps",
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run('pip install -q segmentation-models-pytorch albumentations pydicom pynrrd wandb tqdm fpdf2 plotly', shell=True)\n",
    "print('âœ“ BaÄŸÄ±mlÄ±lÄ±klar tamam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "siim-link",
   "metadata": {},
   "outputs": [],
   "source": "# Dizinleri oluÅŸtur\nfor d in ['data/raw/global', 'data/processed', 'data/masks/siim', 'checkpoints', 'results']:\n    os.makedirs(d, exist_ok=True)\n\nSIIM_LOCAL = 'data/raw/global/siim'\n\n# EÄŸer eski symlink varsa kaldÄ±r â€” gerÃ§ek dizin yapacaÄŸÄ±z\nif os.path.islink(SIIM_LOCAL):\n    os.unlink(SIIM_LOCAL)\nos.makedirs(SIIM_LOCAL, exist_ok=True)\n\nif SIIM_INPUT:\n    # DICOM gÃ¶rÃ¼ntÃ¼ klasÃ¶rÃ¼nÃ¼ bul\n    dcm_src = None\n    for candidate in ['stage_2_images', 'dicom-images-train', 'images']:\n        p = os.path.join(SIIM_INPUT, candidate)\n        if os.path.isdir(p):\n            dcm_src = p\n            break\n    if dcm_src is None:\n        dcm_src = SIIM_INPUT\n\n    # Symlink (gÃ¶rÃ¼ntÃ¼ler bÃ¼yÃ¼k, kopyalanamaz)\n    dcm_link = os.path.join(SIIM_LOCAL, os.path.basename(dcm_src))\n    if os.path.islink(dcm_link): os.unlink(dcm_link)\n    if not os.path.exists(dcm_link): os.symlink(dcm_src, dcm_link)\n\n    dcm_count = int(subprocess.check_output(\n        f'find \"{dcm_src}\" -name \"*.dcm\" | wc -l', shell=True\n    ).decode().strip())\n    print(f'âœ“ GÃ¶rÃ¼ntÃ¼ler: {os.path.basename(dcm_link)}/ â†’ {dcm_src}')\n    print(f'  DICOM sayÄ±sÄ±: {dcm_count:,}')\n\n    # .dcm_dir pointer dosyasÄ± â€” data_manager symlink'i bypass eder\n    abs_dcm_src = os.path.abspath(dcm_src)\n    with open(f'{SIIM_LOCAL}/.dcm_dir', 'w') as f:\n        f.write(abs_dcm_src + '\\n')\n    print(f'  .dcm_dir â†’ {abs_dcm_src}')\n\n    # RLE CSV kopyala (read-only kaynak â†’ yazÄ±labilir hedef)\n    rle_candidates = (\n        glob.glob(f'{SIIM_INPUT}/stage_2_train.csv') +\n        glob.glob(f'{SIIM_INPUT}/**/stage_2_train.csv', recursive=True) +\n        glob.glob(f'{SIIM_INPUT}/**/*rle*.csv', recursive=True) +\n        glob.glob(f'{SIIM_INPUT}/*rle*.csv')\n    )\n    if rle_candidates:\n        dst = f'{SIIM_LOCAL}/train-rle.csv'\n        shutil.copy(rle_candidates[0], dst)\n        print(f'  RLE CSV: {os.path.basename(rle_candidates[0])} â†’ train-rle.csv ({sum(1 for _ in open(dst)):,} satÄ±r)')\n    else:\n        print('  [!] RLE CSV bulunamadÄ±:', os.listdir(SIIM_INPUT))\nelse:\n    print('[!] SIIM_INPUT None')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manifest",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/data_manager.py --convert_rle\n",
    "!python scripts/data_manager.py --build_manifest\n",
    "\n",
    "import pandas as pd\n",
    "try:\n",
    "    df = pd.read_csv('data/processed/master_manifest.csv')\n",
    "    print(f'\\nâœ“ Manifest: {len(df):,} kayÄ±t')\n",
    "    print(f'  Pozitif : {(df[\"is_pneumo\"]==1).sum():,}')\n",
    "    print(f'  Negatif : {(df[\"is_pneumo\"]==0).sum():,}')\n",
    "    print(f'  Kaynaklar: {df[\"source\"].value_counts().to_dict()}')\n",
    "except Exception as e:\n",
    "    print(f'[!] {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wandb-login",
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB_KEY = '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'\n",
    "import wandb\n",
    "wandb.login(key=WANDB_KEY, relogin=True)\n",
    "USE_WANDB = True\n",
    "print('âœ“ W&B tamam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train",
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT_DIR = '/kaggle/working/checkpoints'\n",
    "os.makedirs(CKPT_DIR, exist_ok=True)\n",
    "WANDB_FLAG = '' if USE_WANDB else '--no_wandb'\n",
    "\n",
    "!python scripts/train_global.py \\\n",
    "    --sources SIIM \\\n",
    "    --encoder efficientnet-b0 \\\n",
    "    --img_size 512 \\\n",
    "    --epochs 50 \\\n",
    "    --batch_size 16 \\\n",
    "    --num_folds 5 \\\n",
    "    --lr 1e-4 \\\n",
    "    {WANDB_FLAG} \\\n",
    "    --checkpoint_dir {CKPT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "results",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in [f'{CKPT_DIR}/global_kfold_results.csv', 'results/global_kfold_results.csv']:\n",
    "    if os.path.exists(p):\n",
    "        df = pd.read_csv(p)\n",
    "        print('=== K-FOLD SONUÃ‡LARI ===')\n",
    "        print(df.to_string(index=False))\n",
    "        print(f'Ortalama Dice: {df[\"best_dice\"].mean():.4f} Â± {df[\"best_dice\"].std():.4f}')\n",
    "        break\n",
    "\n",
    "mp = f'{CKPT_DIR}/global_base_model_meta.json'\n",
    "if os.path.exists(mp):\n",
    "    meta = json.load(open(mp))\n",
    "    print('\\n=== BASE MODEL ===')\n",
    "    for k, v in meta.items(): print(f'  {k}: {v}')\n",
    "\n",
    "ckpts = glob.glob(f'{CKPT_DIR}/**/*.pth', recursive=True)\n",
    "print(f'\\nCheckpoint sayÄ±sÄ±: {len(ckpts)}')\n",
    "for c in sorted(ckpts):\n",
    "    print(f'  {os.path.basename(c):40s}  {os.path.getsize(c)/1e6:.1f} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "package",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT = '/kaggle/working'\n",
    "for src, dst in [\n",
    "    (f'{CKPT_DIR}/global_base_model.pth',      f'{OUTPUT}/global_base_model.pth'),\n",
    "    (f'{CKPT_DIR}/global_base_model_meta.json', f'{OUTPUT}/global_base_model_meta.json'),\n",
    "    (f'{CKPT_DIR}/global_kfold_results.csv',    f'{OUTPUT}/global_kfold_results.csv'),\n",
    "]:\n",
    "    if os.path.exists(src):\n",
    "        shutil.copy(src, dst)\n",
    "        print(f'âœ“ {os.path.basename(src)}')\n",
    "\n",
    "for ckpt in glob.glob(f'{CKPT_DIR}/global_folds/*.pth'):\n",
    "    shutil.copy(ckpt, f'{OUTPUT}/{os.path.basename(ckpt)}')\n",
    "    print(f'âœ“ {os.path.basename(ckpt)}')\n",
    "\n",
    "print('\\nâœ“ Output sekmesinden indirebilirsin')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}