{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "name": "Pneumothorax AI ‚Äî Global Pre-training (T√úBƒ∞TAK 2209-A)"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ü´Å Pneumothorax AI ‚Äî Global Pre-training\n**T√úBƒ∞TAK 2209-A | Ahmet Demir | Dokuz Eyl√ºl √úniversitesi**\n\n**Veri stratejisi ‚Äî Google Drive:**\n- NIH verileri Drive'a bir kez indirilir, sonraki oturumlarda tekrar indirilmez\n- T√ºm checkpoint'ler Drive'a kaydedilir\n- Drive path: `MyDrive/tubitak_pneumothorax/`\n\n**Tahmini s√ºre:** T4 GPU ile ~12 saat (50 epoch, 112k g√∂r√ºnt√º)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 0. GPU Kontrol√º"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print('GPU:', torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'YOK ‚Äî Runtime > GPU se√ß!')\n",
    "print('CUDA:', torch.version.cuda)\n",
    "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 1. Google Drive Baƒüla",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## 2. Projeyi Klonla",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Projeyi Klonla"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 3. Baƒüƒ±mlƒ±lƒ±klarƒ± Y√ºkle"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Baƒüƒ±mlƒ±lƒ±klarƒ± Y√ºkle"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 4. Kaggle API Token Ayarla"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Kaggle API Token Ayarla"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 5. NIH ChestX-ray14 ‚Äî Drive'dan Y√ºkle veya ƒ∞ndir"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import subprocess\n\nNIH_LOCAL = 'data/raw/global/nih'\nos.makedirs(NIH_LOCAL, exist_ok=True)\n\n# ‚îÄ‚îÄ 1) Drive'da veri var mƒ±? ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\ndrive_count = int(subprocess.check_output(\n    f'find {DRIVE_NIH} -name \"*.png\" 2>/dev/null | wc -l', shell=True\n).decode().strip())\n\nif drive_count > 100000:\n    print(f'‚úì Drive\\'da {drive_count:,} NIH g√∂r√ºnt√ºs√º bulundu ‚Äî symlink olu≈üturuluyor...')\n    # Colab'da hƒ±zlƒ± eri≈üim i√ßin sembolik baƒülantƒ±\n    if not os.path.islink(NIH_LOCAL):\n        os.rmdir(NIH_LOCAL)\n        os.symlink(DRIVE_NIH, NIH_LOCAL)\n    print(f'‚úì {NIH_LOCAL} ‚Üí {DRIVE_NIH}')\n\n# ‚îÄ‚îÄ 2) Drive'da yok ‚Üí Kaggle'dan Drive'a indir ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nelse:\n    print(f'Drive\\'da NIH bulunamadƒ± ‚Äî Kaggle\\'dan Drive\\'a indiriliyor (~42 GB)...')\n    print('‚ö†Ô∏è  Bu i≈ülem ~30-60 dakika s√ºrebilir, bir kez yapƒ±lƒ±r.')\n    !kaggle datasets download \\\n        -d nih-chest-xrays/data \\\n        -p {DRIVE_NIH} \\\n        --unzip\n    # Symlink\n    if not os.path.islink(NIH_LOCAL):\n        os.rmdir(NIH_LOCAL)\n        os.symlink(DRIVE_NIH, NIH_LOCAL)\n    downloaded = int(subprocess.check_output(\n        f'find {DRIVE_NIH} -name \"*.png\" | wc -l', shell=True\n    ).decode().strip())\n    print(f'‚úì ƒ∞ndirme tamamlandƒ±: {downloaded:,} g√∂r√ºnt√º ‚Äî Drive\\'a kaydedildi')"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 6. Manifest Olu≈ütur"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Manifest Olu≈ütur"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 7. W&B Giri≈ü"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. W&B Giri≈ü"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 8. Pre-training Ba≈ülat\n\n**T4 GPU'da tahmini s√ºre:**\n- 1 epoch (112k g√∂r√ºnt√º, batch=32): ~14 dakika\n- 50 epoch: ~12 saat\n\n> ‚ö†Ô∏è Colab oturumu ~12 saatte kapanabilir. Checkpoint her fold'dan sonra kaydedilir."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "!python scripts/train_global.py \\\n    --sources NIH \\\n    --encoder efficientnet-b0 \\\n    --img_size 512 \\\n    --epochs 50 \\\n    --batch_size 32 \\\n    --num_folds 5 \\\n    --lr 1e-4 \\\n    --checkpoint_dir {DRIVE_CKPT}"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Pre-training Ba≈ülat\n",
    "\n",
    "**T4 GPU'da tahmini s√ºre:**\n",
    "- 1 epoch (112k g√∂r√ºnt√º, batch=32): ~14 dakika\n",
    "- 50 epoch: ~12 saat\n",
    "\n",
    "> ‚ö†Ô∏è Colab oturumu ~12 saatte kapanabilir. Checkpoint her fold'dan sonra kaydedilir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Checkpoint'i Drive'a Kopyala"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 9. Checkpoint'i Drive'a Kopyala"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import shutil, glob\n\n# Base model\nbase_model = 'checkpoints/global_base_model.pth'\nif os.path.exists(base_model):\n    shutil.copy(base_model, f'{DRIVE_CKPT}/global_base_model.pth')\n    shutil.copy('checkpoints/global_base_model_meta.json',\n                f'{DRIVE_CKPT}/global_base_model_meta.json')\n    print(f'‚úì Base model Drive\\'a kopyalandƒ±')\n\n# T√ºm fold checkpoint'leri\nfor ckpt in glob.glob('checkpoints/global_folds/*.pth'):\n    shutil.copy(ckpt, DRIVE_CKPT)\n    print(f'  ‚Üí {os.path.basename(ckpt)}')\n\n# Results CSV\nresults_csv = 'results/global_kfold_results.csv'\nif os.path.exists(results_csv):\n    shutil.copy(results_csv, DRIVE_CKPT)\n    print(f'‚úì Results CSV kopyalandƒ±')\n\nprint(f'\\n‚úì T√ºm dosyalar Drive\\'a kaydedildi: {DRIVE_CKPT}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# K-Fold sonu√ßlarƒ±\n",
    "try:\n",
    "    df = pd.read_csv('results/global_kfold_results.csv')\n",
    "    print('=== K-FOLD SONU√áLARI ===')\n",
    "    print(df.to_string(index=False))\n",
    "    print(f'\\nOrtalama Dice : {df[\"best_dice\"].mean():.4f} ¬± {df[\"best_dice\"].std():.4f}')\n",
    "    print(f'Ortalama AUC  : {df[\"best_auc\"].mean():.4f} ¬± {df[\"best_auc\"].std():.4f}')\n",
    "except FileNotFoundError:\n",
    "    print('Results CSV bulunamadƒ± ‚Äî eƒüitim hen√ºz bitmemi≈ü olabilir')\n",
    "\n",
    "# Base model meta\n",
    "try:\n",
    "    meta = json.load(open('checkpoints/global_base_model_meta.json'))\n",
    "    print('\\n=== BASE MODEL ===')\n",
    "    for k, v in meta.items():\n",
    "        print(f'  {k}: {v}')\n",
    "except FileNotFoundError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚úÖ Sonraki Adƒ±m ‚Äî Fine-tuning\n",
    "\n",
    "DEU DICOM + NRRD verileri geldiƒüinde:\n",
    "\n",
    "```bash\n",
    "# Checkpoint'i Drive'dan al\n",
    "cp /content/drive/MyDrive/tubitak_pneumothorax/checkpoints/global_base_model.pth checkpoints/\n",
    "\n",
    "# DEU verilerini koy\n",
    "# data/local/dicom/*.dcm\n",
    "# data/local/nrrd/*.nrrd\n",
    "\n",
    "# Fine-tune et (~1-2 saat)\n",
    "python scripts/fine_tune_local.py --freeze_encoder --epochs 20\n",
    "```"
   ]
  }
 ]
}